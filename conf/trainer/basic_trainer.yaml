_target_: lightning.Trainer

default_root_dir: ./lightning_logs

logger: 
  _target_: lightning.pytorch.loggers.WandbLogger
  # log_model: true

callbacks:
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val_rmse
    min_delta: ${trainer.min_delta}
    patience: ${trainer.patience}
    mode: min
  - _target_: chemtorch.components.callbacks.console_summary.ConsoleSummaryCallback
    print_config: true
    print_summary: true
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    # Checkpoints are saved to lightning_logs/<project_name>/<data_pipeline>/<model>/seed_<seed>_<timestamp>/checkpoints
    dirpath: ${trainer.default_root_dir}/${hydra:runtime.choices.data_pipeline}/${hydra:runtime.choices.model}/seed_${seed}_${now:%Y-%m-%d_%H-%M-%S}/checkpoints
    monitor: val_loss
    save_top_k: 1
    save_last: true

accelerator: auto
max_epochs: -1  # set to -1 for no limit
gradient_clip_val: 1.0
patience: 30
min_delta: 0.01

enable_progress_bar: false
