# @package _global_
defaults:
  - /trainer: basic_trainer
  - /data_pipeline: uspto_1k
  - /dataset: token
  - /dataloader: torch_dataloader
  - /model: han
  - /routine: classification
  - /routine/loss: cross_entropy
  - _self_

# LOGGING (Weight and Biases)
log: false
project_name: chemtorch
group_name: token
run_name: null

# INITIALIZATION
seed: 0

tasks:
  - fit
  - test

num_classes: 1000
dataset:
  integer_labels: true
  
trainer:
  max_epochs: 200

runtime_args_from_dataset:
  - vocab_size

# MODEL LOADING
load_model: false
ckpt_path: null